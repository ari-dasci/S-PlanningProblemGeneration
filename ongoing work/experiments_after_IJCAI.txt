>  <logistics>
   <planners=[lama-first, lazy-greedy, lazy-greedy]>
   max_atoms_init_state=15, max_actions_init_state=1, max_actions_goal_state=2.0

   > logs: init_policy\version_204
   > saved_models: both_policies_257

   > Entrenamiento (its=1.5k)
      - Tiempo: 16h (en DaSCI)
      - r_diff (init_policy)= 3 (seguía aumentando, lo paré a mitad)
      - r_eventual=-0.05
      - init_policy_entropy 0.6, goal_policy_entropy en 0.3 (seguía bajando)
      - term_cond_prob init_policy y goal_policy ambas convergen a 0
      - num_objs:
         - city: 2.8 (y subiendo)
         - airport: 3
         - location: 0.2 (y bajando)
         - airplane: 2.3
         - truck: 3
         - package: 6.3


   > Problemas (its=1.5)
      - max_atoms = 20
         - diff = [68.2 52.9 58.1]
            - problemas con 20 átomos
         - diversidad media-alta
            - la mayoría de problemas no tienen locations
            - problemas con 2, 3, 4 y 5 ciudades
            - el número de paquetes varía moderadamente

      - max_atoms = 30
         - diff = [145.6 96.1 87.4]
            - problemas con 30 átomos
         - diversidad media
            - no aumenta el número de ciudades!!! (siguen estando entre 2 y 5)
            - aumenta sobretodo el número de packages

      - max_atoms = 40
         - diff = [233.2 154.6 153.4]
            - problemas con 40 átomos
         - diversidad media
            - se generan problemas con hasta 7 ciudades
            - aumenta sobretodo el número de packages 

   >> Aunque no terminé el entrenamiento, se puede ver que NeSIG no generaliza bien en logistics a problemas más
      grandes:
         - La dificultad escala mal
         - El número de ciudades escala mal


>  <logistics>
   planners=[lama-first, lazy-greedy, lazy-greedy]
   max_atoms_init_state=15, max_actions_init_state=1, max_actions_goal_state=2.0
   init_policy_entropy_coeffs: 0.1, None
   goal_policy_entropy_coeffs: 0.0, None
   <difficulty_rescale_factor=1>
   <new difficulty normalization>

   > Ejecutándose en DaSCI
   > logs: init_policy/version_206
   > saved_models: both_policies_259


>  <logistics>
   planners=[lama-first, lazy-greedy, lazy-greedy]
   max_atoms_init_state=15, max_actions_init_state=1, max_actions_goal_state=2.0
   <init_policy_entropy_coeffs: 0.01, None>
   goal_policy_entropy_coeffs: 0.0, None
   <difficulty_rescale_factor=1>
   <new difficulty normalization>

   > Ejecutándose en casa
   > logs: init_policy/version_203
   > saved_models: both_policies_260

   > Entrenamiento (its=1800)
      - Tiempo (casa): 14h 15min
      - r_diff (goal_policy)= 40 (seguía aumentando)
      - r_eventual=-0.02
      - init_policy_entropy 0.4, goal_policy_entropy 0.2
      - term_cond_prob init_policy y goal_policy ambas convergen a 0
      - num_objs:
         - city: 3
         - airport: 3
         - location: 0.01
         - airplane: 2.1 (y bajando)
         - truck: 3
         - package: 7 
 
   > Problemas (its=1800)
      - max_atoms = 15
         - diff = [51.9 42.3 39.4]
            - todos con 15 átomos
         - diversidad baja
            - Todos los problemas con 3 ciudades
            - Ningún problema con location!
            - Cada ciudad tiene exactamente un airport!!!
              Se generan problemas donde solo se usan aviones,
              pero no camiones!!

      - max_atoms = 20
         - diff = [90.4 73.6 67.]
            - todos con 20 átomos
         - diversidad media-baja
            - Problemas con 3, 4 y 5 ciudades!

      - max_atoms = 30
         - diff = [202.9 155.4 129.3]
            - todos con 30 átomos
         - diversidad media-baja
            - Problemas con hasta 7 ciudades!

      - max_atoms = 40
         - diff = [455.1 306.6 209.1]
            - todos con 40 átomos
         - diversidad media-baja
            - Problemas con hasta 8 ciudades
               - Parece que el num de ciudades ya deja de escalar bien, lo que más aumenta
                 es el número de paquetes

   >> La dificultad escala regular
   >> La diversidad de los problemas es muy baja!
      >>> Necesito aumentar el action entropy coeff
      >>> 0.01 es demasiado bajo!
   >> Quizás necesito entrenar en problemas más grandes
         - Lo que hace que un problema sea difícil puede depender del tamaño!


>  <logistics>
   planners=[lama-first, lazy-greedy, lazy-greedy]
   max_atoms_init_state=15, max_actions_init_state=1, max_actions_goal_state=2.0
   <init_policy_entropy_coeffs: 1, None>
   goal_policy_entropy_coeffs: 0.0, None
   difficulty_rescale_factor=1
   new difficulty normalization

   > Ejecutándose en casa
   > logs: init_policy/version_204
   > saved_models: both_policies_261   


------- MIRAR ESTO

   >> El número de objetos generados con action_entropy_coeffs=1 y 10 son muy parecidos!!!
      - Esto parece indicar que esta forma de generar problemas es la que maximiza la dificultad!
         - Si esto es el caso, quizás esté haciendo overfitting a un tamaño de problemas ->
           debería entrenar en problemas de distintos tamaños, para que aprenda a generalizar

      - Opción 2: quizás el problema es la goal policy (al no tener action_entropy_coeff, converge demasiado
        pronto)
         - Debería hacer experimentos usando goal_policy entropy_coeff

      - Opción 3: quizás la NLM no puede aprender "patrones" para generar problemas más complejos
         - Aumentar el número de capas/predicados
         - Añadir counting operations en reduce para que aprenda a contar

   > Si quiero generar problemas con más de dos ciudades debo:
      - Promover la diversidad de otra forma (ej.: diversity reward)

   >> Si veo que la goal_policy entropy es muy baja, quizás debería usar un goal_policy entropy coeff > 0
